{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f4cda0c-9d9c-4d76-bfca-d6ef2f5644fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2. Modeling\n",
    "\n",
    "This notebook covers the modeling pipeline for the iFood case study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ce6e6e2-2911-45c0-aafe-5659b51ab5b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.1 Setup\n",
    "\n",
    "Import necessary libraries and load processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1e646e4-e111-414a-8db0-f1bef9245aa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, classification_report, confusion_matrix\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b27159d-a465-46cd-8aeb-574167f30943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.2 Load Processed Data\n",
    "\n",
    "Load the processed data from the data/processed directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95f98498-bf93-4319-9579-c871e0ec5911",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "path = \"/Workspace/Users/castrobeneyto@gmail.com/ifood-case/data/processed\"\n",
    "profile_df = pd.read_csv(f\"{path}/profile.csv\")\n",
    "offers_df = pd.read_csv(f\"{path}/offers.csv\")\n",
    "df = pd.read_csv(f\"{path}/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd091b8c-b96d-444e-8985-f1221c5925bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea3533e2-3550-40e4-ac33-274bf8d91f22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.3 Target Specification \n",
    "\n",
    "Defining the Prediction Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "072416dc-dc42-4ea7-8b14-3b9aba3345e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "With the goal of determining which offer to send to each customer, the problem was modeled as a **propensity model** to predict the probability of a successful outcome given a sent offer. To achieve this, we frame it as a supervised binary classification task. First, we need to define what constitutes a “successful” offer.\n",
    "\n",
    "In general, possible event paths for `bogo` and `discount` offers are:\n",
    "\n",
    "- **Successful Offer:** Received → Viewed → Transaction(s) → Completed (**_target = 1_**)\n",
    "\n",
    "- **Unviewed Success:** Received → Transaction(s) → Completed (**_target = 1_**)\n",
    "\n",
    "- **Ineffective Offer:** Received → Viewed (**_target = 0_**)\n",
    "\n",
    "- **Unviewed Offer:** Received (**_target = 0_**)\n",
    "\n",
    "for `informational`:\n",
    "- **Successful Offer:** Received → Viewed → Transaction(s) (**_target = 1_**)\n",
    "\n",
    "- **Ineffective Offer:** Received → Viewed (**_target = 0_**)\n",
    "\n",
    "- **Unviewed Offer:** Received (**_target = 0_**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab8d9aab-3264-4a33-9c03-5ba3bd82d7a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_targets(df):\n",
    "    df = df.copy()\n",
    "    df.sort_values([\"account_id\", \"time_since_test_start\"], inplace=True)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Process data grouped by user\n",
    "    for acc, user_df in df.groupby(\"account_id\"):\n",
    "        \n",
    "        # Iterate over all received offers for the user\n",
    "        received_events = user_df[user_df[\"event\"] == \"offer received\"]\n",
    "\n",
    "        for idx, offer in received_events.iterrows():\n",
    "            offer_id = offer[\"offer_id_unified\"]\n",
    "            offer_type = offer[\"offer_type\"]\n",
    "            t0 = offer[\"time_since_test_start\"]\n",
    "            duration = offer[\"duration\"]\n",
    "            min_value = offer[\"min_value\"]\n",
    "\n",
    "            # Validity window of the offer\n",
    "            t_end = t0 + duration\n",
    "\n",
    "            # Filter all events inside the offer’s validity period\n",
    "            window = user_df[\n",
    "                (user_df[\"time_since_test_start\"] >= t0) &\n",
    "                (user_df[\"time_since_test_start\"] <= t_end)\n",
    "            ]\n",
    "\n",
    "            viewed = \"offer viewed\" in window[\"event\"].values\n",
    "            completed = \"offer completed\" in window[\"event\"].values\n",
    "\n",
    "            transactions = window[window[\"event\"] == \"transaction\"]\n",
    "\n",
    "            # ---------------------------\n",
    "            #   Rules for Informational Offers\n",
    "            # ---------------------------\n",
    "            if offer_type == \"informational\":\n",
    "                if viewed and (len(transactions) > 0):\n",
    "                    target = 1\n",
    "                else:\n",
    "                    target = 0\n",
    "\n",
    "            # ---------------------------\n",
    "            #   Rules for BOGO / Discount Offers\n",
    "            # ---------------------------\n",
    "            else:\n",
    "                if completed:\n",
    "                    target = 1\n",
    "                else:\n",
    "                    target = 0\n",
    "\n",
    "            results.append({\n",
    "                \"account_id\": acc,\n",
    "                \"offer_id_unified\": offer_id,\n",
    "                \"t_received\": t0,\n",
    "                \"offer_type\": offer_type,\n",
    "                \"target\": target\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "ml_df = build_targets(df)\n",
    "ml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20238067-9204-43fa-9a06-9e4cdf50ac4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ml_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b9df914-7f73-4186-a9f0-ad16eb0cc524",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ml_df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e2903bd-1ee3-4abd-b1a4-c899566fdfde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Notes:**\n",
    "\n",
    "- Successes are only valid within each offer’s defined duration window.\n",
    "\n",
    "- For `bogo` and `discount` offers, an `offer completed` event is the only requirement—and is sufficient—to count as a success.\n",
    "\n",
    "- For `informational` offers, success requires both an `offer view` and at least one transaction during the validity window.\n",
    "\n",
    "- There is no transaction ID linked to a specific offer ID, which makes it difficult to attribute financial gains to individual offers.\n",
    "\n",
    "- A single completed event may satisfy more than one received offer, as long as it falls within the validity windows of both offers and they belong to the same offer type (offer_id).\n",
    "\n",
    "- It is not possible to determine whether a given transaction should be associated with an informational offer or exclusively with another offer type.\n",
    "\n",
    "- Even if a customer receives the same offer multiple times, a single instance of satisfying the success rules is enough for the customer to receive a success target for that `offer_id`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a5df79c-4df5-4c0f-ad4d-dacf303d542f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.4 Feature Engineering\n",
    "\n",
    "Prepare features for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51a52341-b0dc-4478-86af-377560d17335",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def feature_engineering(profile_df, offers_df, df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Relevant column subsets\n",
    "    profile_columns = [\n",
    "        'id',\n",
    "        'age',\n",
    "        'credit_card_limit',\n",
    "        'gender',\n",
    "        'registered_on'\n",
    "    ]\n",
    "\n",
    "    offers_columns = [\n",
    "        'id',\n",
    "        'discount_value',\n",
    "        'duration',\n",
    "        'min_value',\n",
    "        'email',\n",
    "        'mobile',\n",
    "        'social',\n",
    "        'web'\n",
    "    ]\n",
    "\n",
    "    # Merge with profile\n",
    "    df = df.merge(profile_df[profile_columns], left_on=\"account_id\", right_on=\"id\", how='left').drop(columns=['id'])\n",
    "\n",
    "    # Merge with offer\n",
    "    df = df.merge(offers_df[offers_columns], left_on=\"offer_id_unified\", right_on=\"id\", how='left').drop(columns=['id'])\n",
    "\n",
    "    # Temporal features of customer registration\n",
    "    reference_date = pd.Timestamp(\"2018-12-31\")\n",
    "    df[\"registered_on\"] = pd.to_datetime(df[\"registered_on\"])\n",
    "    df[\"membership_days\"] = (reference_date - df[\"registered_on\"]).dt.days\n",
    "    df[\"membership_months\"] = df[\"membership_days\"] // 30\n",
    "    df[\"membership_years\"] = df[\"membership_days\"] // 365\n",
    "    df[\"registration_year\"] = df[\"registered_on\"].dt.year\n",
    "    df[\"registration_month\"] = df[\"registered_on\"].dt.month\n",
    "    df[\"registration_day\"] = df[\"registered_on\"].dt.day\n",
    "    df.drop(columns='registered_on', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "final_df = feature_engineering(profile_df, offers_df, ml_df)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4399afe-ae63-4115-8186-d28c3a3874e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = final_df.drop(columns=[\"target\",\"account_id\", \"offer_id_unified\", \"t_received\"])\n",
    "y = final_df[\"target\"]\n",
    "account_ids = final_df[\"account_id\"]\n",
    "categorical_cols = [\"gender\", \"offer_type\"]\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74536c93-496d-4ff4-a516-94c823c4ad0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Notes:**\n",
    "\n",
    "- Variables were created related to the user's registration period, including membership duration in days, months, and years, as well as registration year, month, and day.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd9df33b-68c9-4da1-8e4a-84ba3a424d62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.4 Model Training\n",
    "\n",
    "Train and evaluate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d10c5036-a3ce-4d04-9dba-b9f3a6118dfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def define_models_and_params(random_state=42):\n",
    "    \n",
    "    # 1. Decision Tree Classifier (DT)\n",
    "    dt_params = {\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__min_samples_split': [2, 5]\n",
    "    }\n",
    "    dt_model = ('Decision Tree', DecisionTreeClassifier(random_state=random_state), dt_params)\n",
    "\n",
    "    # 2. Random Forest Classifier (RF)\n",
    "    rf_params = {\n",
    "        'model__n_estimators': [50, 100],\n",
    "        'model__max_depth': [5, 10]\n",
    "    }\n",
    "    rf_model = ('Random Forest', RandomForestClassifier(random_state=random_state, n_jobs=-1), rf_params)\n",
    "\n",
    "    # 3. XGBoost Classifier (XGB)\n",
    "    xgb_params = {\n",
    "        'model__n_estimators': [50, 100],\n",
    "        'model__learning_rate': [0.05, 0.1]\n",
    "    }\n",
    "    xgb_model = ('XGBoost', XGBClassifier(random_state=random_state, eval_metric='logloss', n_jobs=-1), xgb_params)\n",
    "\n",
    "    # 4. CatBoost Classifier (CAT)\n",
    "    cat_params = {\n",
    "        'model__iterations': [50, 100],\n",
    "        'model__depth': [5, 7],\n",
    "        'model__verbose': [0]\n",
    "    }\n",
    "    cat_model = ('CatBoost', CatBoostClassifier(random_state=random_state), cat_params)\n",
    "\n",
    "    return [dt_model, rf_model, xgb_model, cat_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04c4f049-274d-426f-9545-4e0da2b70609",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_preprocessor(categorical_cols, numerical_cols):\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "            (\"num\", \"passthrough\", numerical_cols)\n",
    "        ],\n",
    "        remainder='drop' \n",
    "    )\n",
    "    return preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b0b59d8-915c-4d36-a09f-c86921317887",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def tune_and_evaluate_models(X_train, y_train, X_valid, y_valid, models, preprocessor, groups_train, n_splits=5, scoring='roc_auc', random_state=42):\n",
    "    \"\"\"\n",
    "    Performs GridSearchCV for each model and evaluates the best estimator \n",
    "    on the holdout validation set.\n",
    "    \n",
    "    Returns: A dictionary of results and a dictionary of the best estimators.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    best_estimators = {}\n",
    "    \n",
    "    # Stratified K-Fold for robust CV on the training data\n",
    "    cv_folds = GroupKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    for name, model, params in models:\n",
    "        print(f\"\\n--- Starting Hyperparameter Optimization: {name} ---\")\n",
    "\n",
    "        model_pipeline = Pipeline([\n",
    "            (\"preprocess\", preprocessor),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model_pipeline,\n",
    "            param_grid=params,\n",
    "            scoring=scoring,\n",
    "            cv=cv_folds,\n",
    "            verbose=1,\n",
    "            n_jobs=-1 \n",
    "        )\n",
    "\n",
    "        grid_search.fit(X_train, y_train, groups=groups_train)\n",
    "\n",
    "        best_estimator = grid_search.best_estimator_\n",
    "        best_estimators[name] = best_estimator\n",
    "        y_pred_valid = best_estimator.predict(X_valid)\n",
    "        y_proba_valid = best_estimator.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "        # Metrics\n",
    "        roc_auc = roc_auc_score(y_valid, y_proba_valid)\n",
    "        accuracy = accuracy_score(y_valid, y_pred_valid)\n",
    "        precision = precision_score(y_valid, y_pred_valid, zero_division=0)\n",
    "        recall = recall_score(y_valid, y_pred_valid, zero_division=0)\n",
    "\n",
    "        results[name] = {\n",
    "            'best_cv_score': grid_search.best_score_,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'valid_accuracy': accuracy,\n",
    "            'valid_precision': precision,\n",
    "            'valid_recall': recall,\n",
    "            'valid_roc_auc': roc_auc\n",
    "        }\n",
    "\n",
    "        print(f\"{name} Best Params: {results[name]['best_params']}\")\n",
    "        print(f\"{name} CV {scoring.upper()}: {results[name]['best_cv_score']:.4f}\")\n",
    "        print(f\"{name} Holdout Validation Metrics:\")\n",
    "        print(f\"   Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | ROC AUC: {roc_auc:.4f}\")\n",
    "        \n",
    "    return results, best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "508e0d16-9fe3-4763-8cb6-9460b39f9012",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = create_preprocessor(categorical_cols, numerical_cols)\n",
    "models = define_models_and_params(random_state=42)\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_idx, valid_idx in gss.split(X, y, groups=account_ids):\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    groups_train = account_ids.iloc[train_idx]\n",
    "\n",
    "final_results, final_estimators = tune_and_evaluate_models(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_valid, \n",
    "    y_valid, \n",
    "    models, \n",
    "    preprocessor,\n",
    "    groups_train,\n",
    "    scoring='roc_auc'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c9af56c-98f4-41cc-a319-28d672b5bdc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Notes:**\n",
    "\n",
    "- Four classifier models were tested using a grid search approach: Decision Tree, Random Forest, XGBoost, and CatBoost.\n",
    "\n",
    "- Label Encoding was applied to handle categorical variables such as `gender` and `offer_type`.\n",
    "\n",
    "- Group K-Fold validation was used to prevent any overlap of users between training and validation sets.\n",
    "\n",
    "- Classification metrics including accuracy, precision, and recall were used to evaluate model performance.\n",
    "\n",
    "- ROC AUC was used for model optimization, as this metric is threshold-invariant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1d12731-5cb6-4724-9737-59cffe756a9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.5 Model Evaluation\n",
    "\n",
    "Evaluate model performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "762c6cb5-faa4-4886-a01c-8ed75528a6bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f\"{path}/test.csv\")\n",
    "test_df = build_targets(test_df)\n",
    "test_df = feature_engineering(profile_df, offers_df, test_df)\n",
    "X_test = test_df.drop(columns=[\"target\",\"account_id\", \"offer_id_unified\", \"t_received\"])\n",
    "y_test = test_df[\"target\"]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b047430-2f33-4652-9bc8-c0186aaa5506",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "estimator = final_estimators['Random Forest']\n",
    "y_pred_test = estimator.predict(X_test)\n",
    "y_proba_test = estimator.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_proba_test)\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edf1404d-6b29-4418-9ed4-0431b5cab83b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='crest')\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd4212d0-affe-49de-b0bd-c1d72476011c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Current Efficiency: {test_df.target.value_counts(normalize=True)[1] * 100:.2f}%\")\n",
    "print(f\"Model Efficiency: {precision_score(y_test, y_pred_test) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7d384eb-1e22-4e9c-9f20-7b66e144bfa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Notes:**\n",
    "\n",
    "- The model performs well at identifying the positive class (successful offers), with a recall of **78%**.\n",
    "\n",
    "- Positive class precision of **73.81**% indicates that most positive predictions are correct.\n",
    "\n",
    "- ROC AUC of **0.768** suggests the model discriminates effectively between successful and unsuccessful offers.\n",
    "\n",
    "- Current Efficiency (baseline success rate): **60.12%**\n",
    "\n",
    "- Model Efficiency (precision for positive class): **73.81%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf828996-e1c3-412b-8cce-bf8b81ebc93d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.6 Model Interpretability\n",
    "Assess the impact of each feature on the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c3bc05f-16f6-47aa-b29a-def9b34d146e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = permutation_importance(estimator, X, y, n_repeats=10, random_state=42)\n",
    "\n",
    "perm_df = pd.DataFrame({\n",
    "    \"feature\": X_test.columns,\n",
    "    \"importance_mean\": result.importances_mean,\n",
    "    \"importance_std\": result.importances_std\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "perm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c43230fd-bd09-472c-b61f-0d51cf180fc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Notes:**\n",
    "\n",
    "- **credit_card_limit** and **membership** duration are the most influential features in predicting offer success.\n",
    "\n",
    "- Demographic features like **gender** and **age** also play a notable role.\n",
    "\n",
    "- Behavioral or channel-related features like **email** and **mobile** are less important in this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90a2bfcd-5311-4b02-9e99-a3407fb2a366",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.7 Model Inference\n",
    "\n",
    "Simulation of the model's predictions for new users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b44d3e35-3325-4765-81eb-da74c5e5497b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "new_users_df = pd.read_csv(f\"{path}/users_without_offers.csv\")\n",
    "new_users_df = new_users_df.rename(columns={\"id\": \"account_id\"}).copy()\n",
    "\n",
    "# Temporary keys\n",
    "users = new_users_df.assign(_key=1)\n",
    "offers = offers_df.assign(_key=1)\n",
    "\n",
    "# Cross join\n",
    "df = (\n",
    "    users[[\"_key\", \"account_id\"]]\n",
    "    .merge(offers[[\"_key\", \"id\", \"offer_type\"]], on=\"_key\")\n",
    "    .drop(columns=\"_key\")\n",
    ")\n",
    "\n",
    "df = df.rename(columns={\"id\": \"offer_id_unified\"})\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e6beb2e-6479-411a-a997-922661cc7975",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_new_users = feature_engineering(profile_df, offers_df, df).drop(columns=[\"account_id\", \"offer_id_unified\"])\n",
    "X_new_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2223cce3-c27e-436e-a202-cc260c0b9503",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df['score'] = estimator.predict_proba(X_new_users)[:, 1]\n",
    "df.sort_values(by=['account_id', 'score'], ascending=[True, False], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01a1326a-bcf9-4fa2-b770-838aae005531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_max = df.loc[df.groupby('account_id')['score'].idxmax()].sort_values('score', ascending=False)\n",
    "df_max.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_max[['account_id', 'offer_id_unified', 'offer_type', 'score']].style.background_gradient(\n",
    "    subset=['score'], cmap='crest'\n",
    ").set_table_styles([{'selector': 'td', 'props': [('font-size', '11pt')]}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9edf680-82ae-41fb-a1fe-567ae871fa57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Notes:**\n",
    "\n",
    "- All possible user-offer combinations were generated for new users, allowing the trained model to predict the propensity score for each pair.\n",
    "\n",
    "- Based on these scores, offers can be ranked to recommend the best option for each user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "093a6f51-b67b-4bab-bcef-05c23df52893",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.8 Conclusions\n",
    "\n",
    "### 2.8.1 Summary\n",
    "\n",
    "- Developed a propensity model to predict the probability of success for a given offer.\n",
    "\n",
    "- Increased Current Efficiency (baseline success rate) from **60.12%** to **73.81%**.\n",
    "\n",
    "- Enabled offer ranking and recommendation for each customer.\n",
    "\n",
    "### 2.8.2 Improvements\n",
    "\n",
    "- Further exploration and engineering of new features.\n",
    "\n",
    "- Optimize decision thresholds for improved performance.\n",
    "\n",
    "- Refine feature selection to remove less relevant variables.\n",
    "\n",
    "- Develop a model to predict not only the best offer, but also the optimal timing to send it.\n",
    "\n",
    "- Enhance model selection using Bayesian optimization.\n",
    "\n",
    "- Use SHAP or other explainability tools to understand why certain offers are recommended, supporting trust in deployment.\n",
    "\n",
    "- Track transactions for each offer to attribute financial returns to the offers sent.\n",
    "\n",
    "### 2.8.3 Next Steps\n",
    "\n",
    "- Deploy the model in a controlled environment to validate real-world performance and compare against baseline strategies.\n",
    "\n",
    "- Conduct a randomized controlled experiment to evaluate the causal impact of offers and develop an uplift model."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "-r /Workspace/Users/castrobeneyto@gmail.com/ifood-case/requirements.txt"
    ],
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2_modeling",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
